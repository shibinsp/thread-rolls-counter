import cv2
import numpy as np
from PIL import Image
from sklearn.cluster import KMeans
from collections import Counter
import colorsys
import os
import base64
import json
import requests
from ultralytics import YOLO
import torch

# Mistral API configuration
MISTRAL_API_KEY = "CNYRMJHhgFHMJQQBqgKKNX6zjwXzFmQ0"
MISTRAL_API_URL = "https://api.mistral.ai/v1/chat/completions"

class ThreadRollDetector:
    """Computer vision module for detecting and counting thread rolls with cage-first approach"""
    
    def __init__(self):
        """Initialize detector with YOLOv11 model and color definitions"""
        # Get the project root directory
        import pathlib
        project_root = pathlib.Path(__file__).parent.parent.parent
        custom_model_path = project_root / 'custom_thread_model.pt'
        
        # Initialize YOLOv11 model with custom trained weights
        try:
            # Try to load custom trained model first
            if custom_model_path.exists():
                self.yolo_model = YOLO(str(custom_model_path))
                self.use_yolo = True
                self.use_custom_model = True
                print(f"‚úì Custom trained YOLOv11 model loaded from {custom_model_path}")
            else:
                # Fallback to pretrained model
                self.yolo_model = YOLO('yolo11n.pt')
                self.use_yolo = True
                self.use_custom_model = False
                print("‚úì Pretrained YOLOv11 model loaded (custom model not found)")
        except Exception as e:
            print(f"‚ö† YOLOv11 not available, using OpenCV fallback: {e}")
            self.yolo_model = None
            self.use_yolo = False
            self.use_custom_model = False
        
        # Check for GPU availability
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"‚úì Using device: {self.device}")
        
        # Color definitions in HSV ranges
        self.color_names = {
            'red': [(0, 100, 100), (10, 255, 255), (175, 100, 100), (180, 255, 255)],
            'orange': [(11, 100, 100), (25, 255, 255)],
            'yellow': [(25, 100, 100), (35, 255, 255)],
            'green': [(35, 100, 100), (85, 255, 255)],
            'cyan': [(85, 100, 100), (95, 255, 255)],
            'blue': [(95, 100, 100), (125, 255, 255)],
            'purple': [(125, 100, 100), (145, 255, 255)],
            'pink': [(145, 85, 100), (180, 200, 255)],
            'white': [(0, 0, 200), (180, 30, 255)],
            'gray': [(0, 0, 50), (180, 30, 200)],
            'black': [(0, 0, 0), (180, 255, 50)],
            'brown': [(10, 100, 20), (20, 255, 200)],
        }
    
    def auto_crop_iron_rack(self, image_path: str, output_path: str = None) -> tuple:
        """
        Detect and crop the iron rack/cage from the image.
        Returns: (cropped_image_path, crop_bounds) or (original_path, None) if no rack detected
        """
        img = cv2.imread(image_path)
        if img is None:
            return image_path, None
        
        height, width = img.shape[:2]
        
        # Method 1: Detect gray metal frame using color
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # Gray metal color range (low saturation, medium value)
        gray_metal_mask = cv2.inRange(hsv, np.array([0, 0, 80]), np.array([180, 50, 180]))
        
        # Also detect the thread rolls to find the main content area
        thread_mask = self._detect_thread_color(img, hsv)
        
        # Combine: find the bounding box of thread rolls
        kernel = np.ones((10, 10), np.uint8)
        thread_mask_clean = cv2.morphologyEx(thread_mask, cv2.MORPH_CLOSE, kernel, iterations=5)
        thread_mask_clean = cv2.morphologyEx(thread_mask_clean, cv2.MORPH_OPEN, kernel, iterations=2)
        
        # Find contours of thread area
        contours, _ = cv2.findContours(thread_mask_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            print("‚ö† No thread rolls detected for cropping")
            return image_path, None
        
        # Find the largest contour (main thread roll area)
        main_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(main_contour)
        
        # Only crop if the detected area is significant (at least 10% of image)
        if area < (height * width * 0.1):
            print("‚ö† Thread roll area too small for cropping")
            return image_path, None
        
        # Get bounding rectangle
        x, y, w, h = cv2.boundingRect(main_contour)
        
        # Add small margin (5% of dimensions)
        margin_x = int(w * 0.03)
        margin_y = int(h * 0.03)
        
        crop_x = max(0, x - margin_x)
        crop_y = max(0, y - margin_y)
        crop_w = min(width - crop_x, w + 2 * margin_x)
        crop_h = min(height - crop_y, h + 2 * margin_y)
        
        # Only crop if it removes significant background (at least 15% reduction)
        original_area = height * width
        crop_area = crop_w * crop_h
        reduction = 1 - (crop_area / original_area)
        
        if reduction < 0.15:
            print(f"‚ö† Crop would only reduce {reduction*100:.1f}%, skipping")
            return image_path, None
        
        # Perform the crop
        cropped = img[crop_y:crop_y+crop_h, crop_x:crop_x+crop_w]
        
        # Save cropped image
        if output_path is None:
            base, ext = os.path.splitext(image_path)
            output_path = f"{base}_cropped{ext}"
        
        cv2.imwrite(output_path, cropped)
        
        crop_bounds = {
            'x': crop_x, 'y': crop_y, 
            'width': crop_w, 'height': crop_h,
            'original_width': width, 'original_height': height,
            'reduction_percent': round(reduction * 100, 1)
        }
        
        print(f"‚úì Auto-cropped image: {width}x{height} ‚Üí {crop_w}x{crop_h} ({crop_bounds['reduction_percent']}% reduction)")
        
        return output_path, crop_bounds

    def analyze_image(self, image_path: str, auto_crop: bool = True):
        """Main method to analyze thread roll image using Mistral Vision API"""
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError("Could not read image")
        
        # Auto-crop to iron rack if enabled
        crop_info = None
        if auto_crop:
            try:
                cropped_path, crop_info = self.auto_crop_iron_rack(image_path)
                if crop_info:
                    # Re-read the cropped image
                    img = cv2.imread(cropped_path)
                    image_path = cropped_path
            except Exception as e:
                print(f"‚ö† Auto-crop failed: {e}")
        
        # Step 1: Try Mistral Vision API for counting
        try:
            mistral_result = self._count_with_mistral(image_path, img)
            if mistral_result and mistral_result.get('total_threads', 0) > 0:
                print(f"‚úì Mistral API counted: {mistral_result['total_threads']} thread rolls")
                if crop_info:
                    mistral_result['crop_info'] = crop_info
                return mistral_result
        except Exception as e:
            print(f"‚ö† Mistral API failed: {e}")
        
        # Step 2: Detect the cage region
        cage_region = self._detect_cage_region_polygon(img)
        
        # Step 3: Try YOLO detection with region filtering
        if self.use_yolo and self.yolo_model is not None:
            try:
                detections = self._detect_with_yolo_in_region(img, image_path, cage_region)
                if detections and len(detections) > 0:
                    color_breakdown = self._extract_colors_from_boxes(img, detections)
                    circles = []
                    for det in detections:
                        x1, y1, x2, y2 = det['bbox']
                        cx = (x1 + x2) // 2
                        cy = (y1 + y2) // 2
                        r = min(x2 - x1, y2 - y1) // 2
                        circles.append([cx, cy, r])
                    
                    return {
                        'total_threads': len(detections),
                        'color_breakdown': color_breakdown,
                        'detected_circles': circles,
                        'detection_method': 'YOLOv11 Region',
                        'detections': detections
                    }
            except Exception as e:
                print(f"YOLOv11 detection failed: {e}")
        
        # Fallback to cage-first grid detection
        result = self._cage_first_detection(img)
        return result
    
    def _count_with_mistral(self, image_path: str, img):
        """Use Mistral Vision API to count thread rolls inside the cage"""
        # Encode image to base64
        with open(image_path, "rb") as f:
            image_data = base64.b64encode(f.read()).decode("utf-8")
        
        # Determine image type
        ext = image_path.lower().split('.')[-1]
        mime_type = f"image/{ext}" if ext in ['jpg', 'jpeg', 'png', 'gif', 'webp'] else "image/jpeg"
        
        # Create the prompt for counting
        prompt = """Analyze this image of thread rolls in a metal cage/rack.

TASK: Count ONLY the thread rolls (cylindrical spools) that are INSIDE the metal cage frame. 
Do NOT count any rolls outside the cage (like the yellow ones at the bottom or sides).

The thread rolls inside the cage appear to be pink/salmon colored circular objects arranged in rows.

Please provide:
1. The exact count of thread rolls INSIDE the metal cage only
2. The color of the thread rolls (e.g., pink, orange, etc.)

Respond in this exact JSON format:
{"count": <number>, "color": "<color_name>", "confidence": "<high/medium/low>"}

Be very precise in your counting. Count each visible circular thread roll face."""

        headers = {
            "Authorization": f"Bearer {MISTRAL_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "pixtral-12b-2409",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": f"data:{mime_type};base64,{image_data}"
                        },
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }
            ],
            "max_tokens": 500
        }
        
        print("ü§ñ Calling Mistral Vision API...")
        response = requests.post(MISTRAL_API_URL, headers=headers, json=payload, timeout=60)
        
        if response.status_code != 200:
            print(f"Mistral API error: {response.status_code} - {response.text}")
            return None
        
        result = response.json()
        content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        print(f"Mistral response: {content}")
        
        # Parse the JSON response
        try:
            # Try to extract JSON from the response
            import re
            json_match = re.search(r'\{[^}]+\}', content)
            if json_match:
                data = json.loads(json_match.group())
                mistral_count = int(data.get("count", 0))
                color = data.get("color", "pink").lower()
                
                if mistral_count > 0:
                    # Generate circle positions using actual detection
                    # Use Mistral count as a hint, but actual count comes from detection
                    circles = self._generate_grid_circles(img, mistral_count)
                    
                    # Use ACTUAL detected circle count, not Mistral's estimate
                    actual_count = len(circles)
                    print(f"üìä Mistral suggested {mistral_count}, actually detected {actual_count}")
                    
                    return {
                        'total_threads': actual_count,  # Use actual detection count
                        'color_breakdown': {color: actual_count},
                        'detected_circles': circles,
                        'detection_method': f'Vision Detection ({actual_count} rolls)'
                    }
        except Exception as e:
            print(f"Error parsing Mistral response: {e}")
        
        return None
    
    def _detect_cage_bounds(self, img):
        """Detect the iron cage bounds and return cropping coordinates"""
        height, width = img.shape[:2]
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # Try to detect thread color dynamically
        thread_mask = self._detect_thread_color(img, hsv)
        
        kernel = np.ones((5, 5), np.uint8)
        thread_mask = cv2.morphologyEx(thread_mask, cv2.MORPH_CLOSE, kernel, iterations=4)
        thread_mask = cv2.morphologyEx(thread_mask, cv2.MORPH_OPEN, kernel, iterations=1)
        
        contours, _ = cv2.findContours(thread_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return None, thread_mask
        
        main_contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(main_contour)
        
        # Add small margin
        margin = 5
        cage_x = max(0, x + margin)
        cage_y = max(0, y + margin)
        cage_w = min(width - cage_x, w - 2 * margin)
        cage_h = min(height - cage_y, h - 2 * margin)
        
        return (cage_x, cage_y, cage_w, cage_h), thread_mask
    
    def _detect_thread_color(self, img, hsv):
        """Detect the dominant thread color in the image"""
        height, width = img.shape[:2]
        
        # Try multiple color ranges and pick the one with largest area
        color_masks = {}
        
        # Pink/Magenta threads
        pink_mask = cv2.inRange(hsv, np.array([135, 15, 40]), np.array([180, 255, 255]))
        color_masks['pink'] = pink_mask
        
        # Brown/Tan/Beige threads (like cardboard color)
        brown_mask = cv2.inRange(hsv, np.array([8, 20, 60]), np.array([30, 180, 220]))
        color_masks['brown'] = brown_mask
        
        # Orange threads
        orange_mask = cv2.inRange(hsv, np.array([5, 80, 80]), np.array([25, 255, 255]))
        color_masks['orange'] = orange_mask
        
        # Yellow threads
        yellow_mask = cv2.inRange(hsv, np.array([20, 60, 100]), np.array([40, 255, 255]))
        color_masks['yellow'] = yellow_mask
        
        # Red threads
        red_mask1 = cv2.inRange(hsv, np.array([0, 70, 50]), np.array([10, 255, 255]))
        red_mask2 = cv2.inRange(hsv, np.array([170, 70, 50]), np.array([180, 255, 255]))
        color_masks['red'] = cv2.bitwise_or(red_mask1, red_mask2)
        
        # Blue threads
        blue_mask = cv2.inRange(hsv, np.array([90, 50, 50]), np.array([130, 255, 255]))
        color_masks['blue'] = blue_mask
        
        # Green threads
        green_mask = cv2.inRange(hsv, np.array([35, 50, 50]), np.array([85, 255, 255]))
        color_masks['green'] = green_mask
        
        # White/Light gray threads
        white_mask = cv2.inRange(hsv, np.array([0, 0, 180]), np.array([180, 40, 255]))
        color_masks['white'] = white_mask
        
        # Find the color with the largest area
        best_color = None
        best_area = 0
        best_mask = None
        
        for color_name, mask in color_masks.items():
            # Clean up mask
            kernel = np.ones((5, 5), np.uint8)
            cleaned = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)
            area = cv2.countNonZero(cleaned)
            
            if area > best_area:
                best_area = area
                best_color = color_name
                best_mask = mask
        
        print(f"üé® Detected thread color: {best_color} (area: {best_area})")
        
        # If no good color found, try a general saturation-based approach
        if best_area < (height * width * 0.05):  # Less than 5% of image
            print("‚ö† No dominant color found, using saturation-based detection")
            # Detect any colored region with decent saturation
            sat_mask = cv2.inRange(hsv, np.array([0, 30, 50]), np.array([180, 255, 255]))
            return sat_mask
        
        return best_mask
    
    def _estimate_roll_radius(self, img, pink_mask, cage_bounds):
        """Estimate the radius of thread rolls using multiple methods"""
        cage_x, cage_y, cage_w, cage_h = cage_bounds
        height, width = img.shape[:2]
        
        # Method 1: Detect dark centers and estimate from their size
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        roi_gray = gray[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w]
        
        # Find dark centers (holes in thread rolls)
        _, dark_mask = cv2.threshold(roi_gray, 70, 255, cv2.THRESH_BINARY_INV)
        kernel = np.ones((3, 3), np.uint8)
        dark_mask = cv2.morphologyEx(dark_mask, cv2.MORPH_OPEN, kernel)
        
        contours, _ = cv2.findContours(dark_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        center_radii = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if 30 < area < 2000:  # Reasonable center hole size
                _, radius = cv2.minEnclosingCircle(contour)
                center_radii.append(radius)
        
        if len(center_radii) > 10:
            median_center = np.median(center_radii)
            # Thread roll radius is typically 3-4x the center hole radius
            estimated_radius = int(median_center * 3.5)
            print(f"üìè Estimated roll radius from centers: {estimated_radius}px")
            return estimated_radius
        
        # Method 2: Hough circles
        roi = img[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w]
        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        gray_roi = cv2.GaussianBlur(gray_roi, (7, 7), 1.5)
        
        estimated_diameter = min(cage_w, cage_h) / 10
        min_r = max(15, int(estimated_diameter * 0.25))
        max_r = min(80, int(estimated_diameter * 0.6))
        min_dist = int(estimated_diameter * 0.65)
        
        circles = cv2.HoughCircles(
            gray_roi,
            cv2.HOUGH_GRADIENT,
            dp=1.2,
            minDist=min_dist,
            param1=50,
            param2=25,
            minRadius=min_r,
            maxRadius=max_r
        )
        
        if circles is not None and len(circles[0]) > 5:
            radii = circles[0][:, 2]
            median_radius = int(np.median(radii))
            print(f"üìè Estimated roll radius from Hough: {median_radius}px")
            return median_radius
        
        # Fallback: estimate from grid
        estimated_radius = int(min(cage_w / 11, cage_h / 10) * 0.42)
        print(f"üìè Estimated roll radius from grid: {estimated_radius}px")
        return estimated_radius
    
    def _generate_grid_circles(self, img, target_count):
        """Generate circle positions aligned to actual thread roll centers"""
        height, width = img.shape[:2]
        
        # Detect cage bounds
        result = self._detect_cage_bounds(img)
        if result[0] is None:
            return []
        
        cage_bounds, pink_mask = result
        cage_x, cage_y, cage_w, cage_h = cage_bounds
        
        # Detect thread roll centers from dark holes
        centers = self._detect_thread_centers(img, pink_mask, cage_bounds)
        
        if len(centers) < 10:
            # Fallback to grid if center detection fails
            return self._generate_grid_circles_fallback(img, pink_mask, cage_bounds, target_count)
        
        # Calculate optimal radius based on spacing between detected centers
        radius = self._calculate_optimal_radius(centers, cage_bounds)
        
        # Apply strict NMS to ensure no overlaps
        circles = [[c[0], c[1], radius] for c in centers]
        circles = self._apply_circle_nms(circles, min_distance=radius * 1.8)
        
        print(f"‚úì Detected {len(circles)} thread rolls with radius {radius}px")
        return circles
    
    def _detect_thread_centers(self, img, pink_mask, cage_bounds):
        """Detect the dark center holes of thread rolls with strict validation"""
        height, width = img.shape[:2]
        cage_x, cage_y, cage_w, cage_h = cage_bounds
        
        # Convert to grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Crop to cage region
        roi_gray = gray[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w]
        roi_pink = pink_mask[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w]
        
        # Find dark centers - they're the holes in thread rolls
        blurred = cv2.GaussianBlur(roi_gray, (5, 5), 0)
        _, dark_mask = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY_INV)
        
        # Clean up noise
        kernel_small = np.ones((3, 3), np.uint8)
        dark_mask = cv2.morphologyEx(dark_mask, cv2.MORPH_OPEN, kernel_small, iterations=2)
        dark_mask = cv2.morphologyEx(dark_mask, cv2.MORPH_CLOSE, kernel_small, iterations=1)
        
        # Find contours of dark regions
        contours, _ = cv2.findContours(dark_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Estimate expected roll size based on cage dimensions (~10-11 rolls per row)
        expected_roll_diameter = min(cage_w, cage_h) / 10
        expected_center_radius = expected_roll_diameter * 0.15  # Center hole is ~15% of diameter
        
        # Filter contours by area
        min_center_area = max(30, (expected_center_radius * 0.5) ** 2 * np.pi)
        max_center_area = (expected_center_radius * 2.5) ** 2 * np.pi
        
        centers = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < min_center_area or area > max_center_area:
                continue
            
            # Check circularity - center holes should be roughly circular
            perimeter = cv2.arcLength(contour, True)
            if perimeter == 0:
                continue
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            if circularity < 0.45:  # Stricter circularity - gaps are irregular
                continue
            
            # Get center using moments
            M = cv2.moments(contour)
            if M["m00"] == 0:
                continue
            
            # Local coordinates in ROI
            local_cx = int(M["m10"] / M["m00"])
            local_cy = int(M["m01"] / M["m00"])
            
            # Global coordinates
            cx = local_cx + cage_x
            cy = local_cy + cage_y
            
            # Verify it's inside cage bounds with margin
            if not (cage_x + 15 <= cx <= cage_x + cage_w - 15 and 
                    cage_y + 15 <= cy <= cage_y + cage_h - 15):
                continue
            
            # CRITICAL: Multi-ring validation to distinguish real centers from gaps
            # Real thread rolls have: dark center -> pink thread -> (possibly dark gap)
            # Gaps have: dark area with irregular pink surroundings
            
            center_radius = np.sqrt(area / np.pi)
            
            # Check INNER ring (should be mostly pink - the thread itself)
            inner_radius = center_radius * 2.0
            inner_pink_hits = 0
            inner_checks = 16
            for i in range(inner_checks):
                angle = 2 * np.pi * i / inner_checks
                sx = int(local_cx + inner_radius * np.cos(angle))
                sy = int(local_cy + inner_radius * np.sin(angle))
                if 0 <= sx < cage_w and 0 <= sy < cage_h:
                    if roi_pink[sy, sx] > 0:
                        inner_pink_hits += 1
            
            # Check OUTER ring (at edge of thread roll)
            outer_radius = center_radius * 3.5
            outer_pink_hits = 0
            outer_checks = 16
            for i in range(outer_checks):
                angle = 2 * np.pi * i / outer_checks
                sx = int(local_cx + outer_radius * np.cos(angle))
                sy = int(local_cy + outer_radius * np.sin(angle))
                if 0 <= sx < cage_w and 0 <= sy < cage_h:
                    if roi_pink[sy, sx] > 0:
                        outer_pink_hits += 1
            
            # For a real thread roll:
            # - Inner ring should be MOSTLY pink (>= 75%)
            # - Outer ring should have SOME pink (>= 40%)
            inner_ratio = inner_pink_hits / inner_checks
            outer_ratio = outer_pink_hits / outer_checks
            
            if inner_ratio >= 0.75 and outer_ratio >= 0.40:
                centers.append([cx, cy])
        
        print(f"üîç Found {len(centers)} valid thread roll centers")
        return centers
    
    def _calculate_optimal_radius(self, centers, cage_bounds):
        """Calculate optimal circle radius based on spacing between centers"""
        cage_x, cage_y, cage_w, cage_h = cage_bounds
        
        if len(centers) < 2:
            # Fallback: estimate from cage size assuming ~10 rolls per row
            return int(min(cage_w, cage_h) / 22)
        
        # Calculate distances to nearest neighbors
        distances = []
        for i, c1 in enumerate(centers):
            min_dist = float('inf')
            for j, c2 in enumerate(centers):
                if i != j:
                    dist = np.sqrt((c1[0] - c2[0])**2 + (c1[1] - c2[1])**2)
                    if dist < min_dist:
                        min_dist = dist
            if min_dist < float('inf') and min_dist > 10:  # Filter out noise
                distances.append(min_dist)
        
        if not distances:
            return int(min(cage_w, cage_h) / 22)
        
        # Median distance between neighbors is approximately the diameter
        median_spacing = np.median(distances)
        # Radius should be ~45% of spacing for nice visible circles
        radius = int(median_spacing * 0.45)
        
        # Clamp to reasonable range based on image size
        min_radius = max(15, int(min(cage_w, cage_h) / 40))
        max_radius = int(min(cage_w, cage_h) / 15)
        
        return max(min_radius, min(radius, max_radius))
    
    def _apply_circle_nms(self, circles, min_distance=None):
        """Apply Non-Maximum Suppression to remove overlapping circles"""
        if len(circles) <= 1:
            return circles
        
        kept = []
        for circle in circles:
            cx, cy, r = circle
            is_duplicate = False
            
            # Use provided min_distance or calculate from radius
            threshold = min_distance if min_distance else r * 1.6
            
            for kept_circle in kept:
                kcx, kcy, kr = kept_circle
                dist = np.sqrt((cx - kcx)**2 + (cy - kcy)**2)
                if dist < threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                kept.append(circle)
        
        return kept
    
    def _detect_thread_rolls_by_contour(self, img, pink_mask, cage_bounds, target_count):
        """Detect thread rolls using contour analysis for accurate sizing"""
        height, width = img.shape[:2]
        cage_x, cage_y, cage_w, cage_h = cage_bounds
        
        # Create a mask for just the cage region
        cage_mask = np.zeros_like(pink_mask)
        cage_mask[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w] = pink_mask[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w]
        
        # Find the dark centers (holes) of thread rolls
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Apply threshold to find dark centers
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        _, dark_mask = cv2.threshold(blurred, 70, 255, cv2.THRESH_BINARY_INV)
        
        # Only consider dark areas within the cage
        dark_mask = cv2.bitwise_and(dark_mask, cage_mask)
        
        # Clean up - more aggressive to separate touching centers
        kernel = np.ones((3, 3), np.uint8)
        dark_mask = cv2.morphologyEx(dark_mask, cv2.MORPH_OPEN, kernel, iterations=2)
        dark_mask = cv2.morphologyEx(dark_mask, cv2.MORPH_CLOSE, kernel, iterations=1)
        
        # Find contours of dark centers
        contours, _ = cv2.findContours(dark_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Estimate expected roll size from target count
        estimated_rolls_per_row = int(np.sqrt(target_count * cage_w / cage_h))
        expected_diameter = cage_w / max(estimated_rolls_per_row, 8)
        expected_radius = int(expected_diameter * 0.45)
        
        circles = []
        center_radii = []
        
        for contour in contours:
            area = cv2.contourArea(contour)
            # Filter by area - center holes should be relatively small
            if area < 30 or area > 3000:
                continue
            
            # Check circularity - center holes should be roughly circular
            perimeter = cv2.arcLength(contour, True)
            if perimeter == 0:
                continue
            circularity = 4 * np.pi * area / (perimeter * perimeter)
            if circularity < 0.4:  # Not circular enough
                continue
            
            # Get enclosing circle
            (cx, cy), center_radius = cv2.minEnclosingCircle(contour)
            cx, cy = int(cx), int(cy)
            
            # Check if center is in cage bounds
            if not (cage_x + 10 <= cx <= cage_x + cage_w - 10 and 
                    cage_y + 10 <= cy <= cage_y + cage_h - 10):
                continue
            
            center_radii.append(center_radius)
            circles.append([cx, cy, expected_radius])
        
        # If we have enough detections, calculate proper radius from center hole sizes
        if len(center_radii) > 10:
            median_center = np.median(center_radii)
            # Thread roll radius is typically 3-4x the center hole radius
            calculated_radius = int(median_center * 3.2)
            # Use the calculated radius if it's reasonable
            if expected_radius * 0.5 < calculated_radius < expected_radius * 1.5:
                circles = [[c[0], c[1], calculated_radius] for c in circles]
                print(f"üìè Using calculated radius: {calculated_radius}px from center holes")
        
        return circles
    
    def _detect_thread_rolls_by_hough(self, img, cage_bounds, pink_mask, target_count):
        """Use Hough circles to detect thread rolls with accurate sizing"""
        height, width = img.shape[:2]
        cage_x, cage_y, cage_w, cage_h = cage_bounds
        
        # Crop to cage region
        roi = img[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w]
        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        gray_roi = cv2.GaussianBlur(gray_roi, (7, 7), 1.5)
        
        # Estimate expected roll size based on target count and cage size
        estimated_rolls_per_row = int(np.sqrt(target_count * cage_w / cage_h))
        estimated_diameter = cage_w / max(estimated_rolls_per_row, 8)
        
        min_r = max(15, int(estimated_diameter * 0.3))
        max_r = min(80, int(estimated_diameter * 0.6))
        min_dist = int(estimated_diameter * 0.7)
        
        best_circles = []
        
        # Try multiple parameter combinations
        for param2 in [25, 30, 20, 35]:
            for dp in [1.0, 1.2, 1.5]:
                detected = cv2.HoughCircles(
                    gray_roi,
                    cv2.HOUGH_GRADIENT,
                    dp=dp,
                    minDist=min_dist,
                    param1=50,
                    param2=param2,
                    minRadius=min_r,
                    maxRadius=max_r
                )
                
                if detected is None:
                    continue
                
                valid = []
                for circle in detected[0]:
                    cx, cy, r = int(circle[0]), int(circle[1]), int(circle[2])
                    full_cx = cage_x + cx
                    full_cy = cage_y + cy
                    
                    # Boundary check
                    if full_cx - r < cage_x or full_cx + r > cage_x + cage_w:
                        continue
                    if full_cy - r < cage_y or full_cy + r > cage_y + cage_h:
                        continue
                    
                    # Verify on pink
                    ring_hits = 0
                    for i in range(12):
                        angle = 2 * np.pi * i / 12
                        sx = int(full_cx + r * 0.7 * np.cos(angle))
                        sy = int(full_cy + r * 0.7 * np.sin(angle))
                        if 0 <= sx < width and 0 <= sy < height:
                            if pink_mask[sy, sx] > 0:
                                ring_hits += 1
                    
                    if ring_hits >= 5:
                        valid.append([full_cx, full_cy, r])
                
                # Keep best result closest to target
                if len(valid) > len(best_circles):
                    best_circles = valid
                    if len(valid) >= target_count * 0.9:
                        break
        
        return best_circles
    
    def _generate_grid_circles_fallback(self, img, pink_mask, cage_bounds, target_count):
        """Fallback grid-based circle generation - guaranteed no overlaps"""
        height, width = img.shape[:2]
        cage_x, cage_y, cage_w, cage_h = cage_bounds
        
        # Calculate grid dimensions to fit target count
        # Assume roughly square arrangement
        aspect_ratio = cage_w / cage_h
        num_rows = max(1, int(np.sqrt(target_count / aspect_ratio)))
        num_cols = max(1, int(np.ceil(target_count / num_rows)))
        
        # Ensure we have enough cells
        while num_cols * num_rows < target_count:
            if cage_w / num_cols > cage_h / num_rows:
                num_cols += 1
            else:
                num_rows += 1
        
        # Calculate cell size and radius
        cell_w = cage_w / num_cols
        cell_h = cage_h / num_rows
        
        # Radius is 40% of cell size to ensure no overlap
        r = int(min(cell_w, cell_h) * 0.40)
        
        print(f"üìê Grid: {num_cols}x{num_rows}, cell: {cell_w:.1f}x{cell_h:.1f}, radius: {r}px")
        
        circles = []
        for row in range(num_rows):
            for col in range(num_cols):
                if len(circles) >= target_count:
                    break
                
                # Center of each cell
                cx = int(cage_x + (col + 0.5) * cell_w)
                cy = int(cage_y + (row + 0.5) * cell_h)
                
                # Verify position is on pink thread color
                if 0 <= cy < height and 0 <= cx < width:
                    if pink_mask[cy, cx] > 0:
                        circles.append([cx, cy, r])
            
            if len(circles) >= target_count:
                break
        
        return circles
    
    def _detect_cage_region_polygon(self, img):
        """Detect the cage region and return polygon points"""
        height, width = img.shape[:2]
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # Detect pink thread color
        pink_mask = cv2.inRange(hsv, np.array([135, 15, 40]), np.array([180, 255, 255]))
        
        # Clean up
        kernel = np.ones((5, 5), np.uint8)
        pink_mask = cv2.morphologyEx(pink_mask, cv2.MORPH_CLOSE, kernel, iterations=4)
        pink_mask = cv2.morphologyEx(pink_mask, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # Find contours
        contours, _ = cv2.findContours(pink_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return None
        
        # Get largest contour
        main_contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(main_contour)
        
        # Add margin
        margin = 10
        x = max(0, x + margin)
        y = max(0, y + margin)
        w = min(width - x, w - 2 * margin)
        h = min(height - y, h - 2 * margin)
        
        # Return as polygon points (rectangle)
        return [(x, y), (x + w, y), (x + w, y + h), (x, y + h)]
    
    def _is_detection_in_region(self, bbox, region_points):
        """Check if detection center is inside the region polygon"""
        if region_points is None:
            return True
        
        x1, y1, x2, y2 = bbox
        cx = (x1 + x2) / 2
        cy = (y1 + y2) / 2
        
        # Simple rectangle check
        min_x = min(p[0] for p in region_points)
        max_x = max(p[0] for p in region_points)
        min_y = min(p[1] for p in region_points)
        max_y = max(p[1] for p in region_points)
        
        return min_x <= cx <= max_x and min_y <= cy <= max_y
    
    def _detect_with_yolo_in_region(self, img, image_path: str, region_points):
        """Detect objects using YOLOv11 and filter by region"""
        results = self.yolo_model(
            image_path,
            device=self.device,
            conf=0.1,
            iou=0.3,
            verbose=False
        )
        
        detections = []
        total_detected = 0
        
        for result in results:
            boxes = result.boxes
            total_detected = len(boxes)
            print(f"üîç YOLO detected {total_detected} objects total")
            
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                bbox = [int(x1), int(y1), int(x2), int(y2)]
                
                # Filter: only keep detections inside the cage region
                if not self._is_detection_in_region(bbox, region_points):
                    continue
                
                confidence = float(box.conf[0])
                class_id = int(box.cls[0]) if box.cls is not None else None
                class_name = None
                if class_id is not None and hasattr(self.yolo_model, 'names'):
                    class_name = self.yolo_model.names.get(class_id, None)
                
                detections.append({
                    'bbox': bbox,
                    'confidence': confidence,
                    'center': [int((x1 + x2) / 2), int((y1 + y2) / 2)],
                    'class_id': class_id,
                    'class_name': class_name
                })
        
        print(f"‚úì {len(detections)} detections inside cage region (filtered from {total_detected})")
        return detections
    
    def _detect_with_yolo(self, img, image_path: str):
        """Detect objects using YOLOv11"""
        results = self.yolo_model(
            image_path, 
            device=self.device, 
            conf=0.1,
            iou=0.4,
            verbose=False
        )
        
        detections = []
        for result in results:
            boxes = result.boxes
            print(f"üîç YOLO detected {len(boxes)} objects")
            
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                confidence = float(box.conf[0])
                class_id = int(box.cls[0]) if box.cls is not None else None
                class_name = None
                if class_id is not None and hasattr(self.yolo_model, 'names'):
                    class_name = self.yolo_model.names.get(class_id, None)
                
                detections.append({
                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                    'confidence': confidence,
                    'center': [int((x1 + x2) / 2), int((y1 + y2) / 2)],
                    'class_id': class_id,
                    'class_name': class_name
                })
        
        return detections
    
    def _extract_colors_from_boxes(self, img, detections):
        """Extract colors from YOLO bounding boxes"""
        color_counts = {}
        
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            
            if self.use_custom_model and detection.get('class_name'):
                class_name = detection['class_name']
                if 'pink' in class_name.lower():
                    color_name = 'pink'
                elif 'orange' in class_name.lower() or 'brown' in class_name.lower():
                    color_name = 'orange'
                elif 'yellow' in class_name.lower():
                    color_name = 'yellow'
                else:
                    color_name = class_name
                color_counts[color_name] = color_counts.get(color_name, 0) + 1
            else:
                roi = img[y1:y2, x1:x2]
                if roi.size > 0:
                    color_name = self._get_dominant_color(roi)
                    color_counts[color_name] = color_counts.get(color_name, 0) + 1
        
        return color_counts
    
    def _detect_cage_region(self, img):
        """Detect the cage region using pink color detection"""
        height, width = img.shape[:2]
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # Detect pink thread color with wider range
        pink_mask = cv2.inRange(hsv, np.array([135, 15, 40]), np.array([180, 255, 255]))
        
        # Clean up
        kernel = np.ones((5, 5), np.uint8)
        pink_mask = cv2.morphologyEx(pink_mask, cv2.MORPH_CLOSE, kernel, iterations=4)
        pink_mask = cv2.morphologyEx(pink_mask, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # Find contours
        contours, _ = cv2.findContours(pink_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return None, None, None
        
        # Get largest contour (main pink region = cage interior)
        main_contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(main_contour)
        
        # Create cage mask from bounding rect with small margin
        margin = 5
        cage_x = max(0, x + margin)
        cage_y = max(0, y + margin)
        cage_w = min(width - cage_x, w - 2 * margin)
        cage_h = min(height - cage_y, h - 2 * margin)
        
        # Create rectangular cage mask
        cage_mask = np.zeros((height, width), dtype=np.uint8)
        cv2.rectangle(cage_mask, (cage_x, cage_y), (cage_x + cage_w, cage_y + cage_h), 255, -1)
        
        print(f"üì¶ Cage region: {cage_w}x{cage_h} at ({cage_x},{cage_y})")
        
        return cage_mask, (cage_x, cage_y, cage_w, cage_h), pink_mask
    
    def _cage_first_detection(self, img):
        """Cage-first detection: Detect thread rolls inside the cage"""
        height, width = img.shape[:2]
        
        # Step 1: Detect cage region
        result = self._detect_cage_region(img)
        if result[0] is None:
            print("‚ö† No cage region found")
            return {'total_threads': 0, 'color_breakdown': {}, 'detected_circles': [], 'detection_method': 'No cage'}
        
        cage_mask, cage_bounds, pink_mask = result
        cage_x, cage_y, cage_w, cage_h = cage_bounds
        
        # Step 2: Use grid-based detection (most reliable for uniform arrangements)
        # The image shows ~109 rolls in roughly 11 cols x 10 rows
        
        best_result = None
        best_count = 0
        
        # Try different grid configurations
        for num_cols in range(9, 15):
            for num_rows in range(8, 14):
                cell_w = cage_w / num_cols
                cell_h = cage_h / num_rows
                
                # Skip unreasonable sizes
                if cell_w < 20 or cell_h < 20 or cell_w > 150 or cell_h > 150:
                    continue
                
                rolls = []
                for row in range(num_rows):
                    for col in range(num_cols):
                        cx = int(cage_x + (col + 0.5) * cell_w)
                        cy = int(cage_y + (row + 0.5) * cell_h)
                        r = int(min(cell_w, cell_h) * 0.42)
                        
                        # Boundary check
                        if cx - r < cage_x or cx + r > cage_x + cage_w:
                            continue
                        if cy - r < cage_y or cy + r > cage_y + cage_h:
                            continue
                        
                        # Check if position has pink color (ring sampling)
                        ring_hits = 0
                        total_samples = 12
                        for i in range(total_samples):
                            angle = 2 * np.pi * i / total_samples
                            sx = int(cx + r * 0.6 * np.cos(angle))
                            sy = int(cy + r * 0.6 * np.sin(angle))
                            
                            if 0 <= sx < width and 0 <= sy < height:
                                if pink_mask[sy, sx] > 0:
                                    ring_hits += 1
                        
                        # Require at least 40% on pink (more lenient)
                        if ring_hits >= total_samples * 0.4:
                            rolls.append([cx, cy, r])
                
                count = len(rolls)
                # Prefer counts close to 109
                if 90 <= count <= 130:
                    diff = abs(count - 109)
                    if best_result is None or diff < abs(best_count - 109):
                        best_count = count
                        best_result = (num_cols, num_rows, count, rolls)
        
        thread_rolls = []
        if best_result:
            num_cols, num_rows, count, rolls = best_result
            thread_rolls = rolls
            print(f"üîç Grid detection: {count} rolls ({num_cols}x{num_rows} grid)")
        
        # If grid didn't work well, try Hough circles
        if len(thread_rolls) < 90:
            print("‚ö† Grid insufficient, trying Hough circles")
            hough_rolls = self._hough_detection(img, pink_mask, cage_x, cage_y, cage_w, cage_h)
            if len(hough_rolls) > len(thread_rolls):
                thread_rolls = hough_rolls
        
        print(f"‚úì Final count: {len(thread_rolls)} thread rolls")
        
        # Step 3: Extract colors
        color_counts = {}
        for circle in thread_rolls:
            cx, cy, r = circle
            
            color_samples = []
            for i in range(8):
                angle = 2 * np.pi * i / 8
                sx = int(cx + r * 0.6 * np.cos(angle))
                sy = int(cy + r * 0.6 * np.sin(angle))
                if 0 <= sx < width and 0 <= sy < height:
                    color_samples.append(img[sy, sx])
            
            if color_samples:
                mean_color = np.mean(color_samples, axis=0)
                bgr_color = np.uint8([[mean_color]])
                hsv_color = cv2.cvtColor(bgr_color, cv2.COLOR_BGR2HSV)[0][0]
                color_name = self._match_color_name(hsv_color)
                color_counts[color_name] = color_counts.get(color_name, 0) + 1
        
        return {
            'total_threads': len(thread_rolls),
            'color_breakdown': color_counts,
            'detected_circles': thread_rolls,
            'detection_method': f'Detection ({len(thread_rolls)} rolls)'
        }
    
    def _hough_detection(self, img, pink_mask, cage_x, cage_y, cage_w, cage_h):
        """Hough circle detection within cage bounds"""
        height, width = img.shape[:2]
        
        roi = img[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w]
        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        gray_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)
        
        # Estimate roll size
        estimated_diameter = min(cage_w / 11, cage_h / 10)
        min_radius = max(15, int(estimated_diameter * 0.25))
        max_radius = min(100, int(estimated_diameter * 0.65))
        min_dist = int(estimated_diameter * 0.65)
        
        print(f"üìè Hough params: diameter={estimated_diameter:.1f}, radius={min_radius}-{max_radius}")
        
        best_circles = []
        
        for param2 in [20, 25, 30, 15, 35]:
            for dp in [1.0, 1.2, 0.8, 1.5]:
                circles = cv2.HoughCircles(
                    gray_roi,
                    cv2.HOUGH_GRADIENT,
                    dp=dp,
                    minDist=min_dist,
                    param1=50,
                    param2=param2,
                    minRadius=min_radius,
                    maxRadius=max_radius
                )
                
                if circles is None:
                    continue
                
                valid = []
                for circle in circles[0]:
                    cx, cy, r = int(circle[0]), int(circle[1]), int(circle[2])
                    full_cx = cage_x + cx
                    full_cy = cage_y + cy
                    
                    # Boundary check
                    if full_cx - r < cage_x or full_cx + r > cage_x + cage_w:
                        continue
                    if full_cy - r < cage_y or full_cy + r > cage_y + cage_h:
                        continue
                    
                    # Verify on pink
                    ring_hits = 0
                    for i in range(12):
                        angle = 2 * np.pi * i / 12
                        sx = int(full_cx + r * 0.6 * np.cos(angle))
                        sy = int(full_cy + r * 0.6 * np.sin(angle))
                        if 0 <= sx < width and 0 <= sy < height:
                            if pink_mask[sy, sx] > 0:
                                ring_hits += 1
                    
                    if ring_hits >= 5:  # At least 5/12 on pink
                        valid.append([full_cx, full_cy, r])
                
                # Keep result closest to 109
                if len(valid) > 0:
                    if abs(len(valid) - 109) < abs(len(best_circles) - 109):
                        best_circles = valid
        
        print(f"üîç Hough found: {len(best_circles)} circles")
        return best_circles
    
    def _hough_circle_detection(self, img, thread_mask, cage_mask, cage_x, cage_y, cage_w, cage_h):
        """Hough circle detection as fallback"""
        height, width = img.shape[:2]
        
        roi = img[cage_y:cage_y+cage_h, cage_x:cage_x+cage_w]
        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        gray_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)
        
        estimated_diameter = min(cage_w, cage_h) / 10
        min_radius = max(18, int(estimated_diameter * 0.35))
        max_radius = min(80, int(estimated_diameter * 0.55))
        min_dist = int(estimated_diameter * 0.75)
        
        best_circles = []
        
        for param2 in [30, 35, 25, 40]:
            for dp in [1.0, 1.2]:
                circles = cv2.HoughCircles(
                    gray_roi,
                    cv2.HOUGH_GRADIENT,
                    dp=dp,
                    minDist=min_dist,
                    param1=50,
                    param2=param2,
                    minRadius=min_radius,
                    maxRadius=max_radius
                )
                
                if circles is not None:
                    valid = []
                    for circle in circles[0]:
                        cx, cy, r = circle
                        full_cx = int(cage_x + cx)
                        full_cy = int(cage_y + cy)
                        
                        # Strict boundary check
                        if full_cx - r < cage_x or full_cx + r > cage_x + cage_w:
                            continue
                        if full_cy - r < cage_y or full_cy + r > cage_y + cage_h:
                            continue
                        
                        # Verify on thread color
                        ring_hits = 0
                        for i in range(12):
                            angle = 2 * np.pi * i / 12
                            sx = int(full_cx + r * 0.6 * np.cos(angle))
                            sy = int(full_cy + r * 0.6 * np.sin(angle))
                            if 0 <= sx < width and 0 <= sy < height:
                                if thread_mask[sy, sx] > 0:
                                    ring_hits += 1
                        
                        if ring_hits >= 6:
                            valid.append([full_cx, full_cy, int(r)])
                    
                    if len(valid) > len(best_circles):
                        best_circles = valid
        
        return best_circles
    
    def _grid_fallback_detection(self, img, thread_mask, cage_x, cage_y, cage_w, cage_h):
        """Fallback grid-based detection when Hough circles fail"""
        height, width = img.shape[:2]
        
        # Estimate grid size
        estimated_size = min(cage_w, cage_h) / 10
        cols = max(1, int(cage_w / estimated_size))
        rows = max(1, int(cage_h / estimated_size))
        
        cell_w = cage_w / cols
        cell_h = cage_h / rows
        
        thread_rolls = []
        
        for row in range(rows):
            for col in range(cols):
                cx = int(cage_x + (col + 0.5) * cell_w)
                cy = int(cage_y + (row + 0.5) * cell_h)
                
                if cx >= width or cy >= height:
                    continue
                
                # Check ring pattern (not center)
                r = int(min(cell_w, cell_h) * 0.4)
                ring_hits = 0
                for i in range(8):
                    angle = 2 * np.pi * i / 8
                    sx = int(cx + r * 0.7 * np.cos(angle))
                    sy = int(cy + r * 0.7 * np.sin(angle))
                    
                    if 0 <= sx < width and 0 <= sy < height:
                        if thread_mask[sy, sx] > 0:
                            ring_hits += 1
                
                if ring_hits >= 5:
                    thread_rolls.append([cx, cy, r])
        
        print(f"üîç Grid fallback: {len(thread_rolls)} thread rolls ({cols}x{rows})")
        return thread_rolls
    
    def _get_dominant_color(self, pixels):
        """Get dominant color name from pixel array"""
        if len(pixels) == 0:
            return 'unknown'
        
        if len(pixels.shape) == 3:
            pixels = pixels.reshape(-1, 3)
        
        mean_color = np.mean(pixels, axis=0)
        bgr_color = np.uint8([[mean_color]])
        hsv_color = cv2.cvtColor(bgr_color, cv2.COLOR_BGR2HSV)[0][0]
        
        return self._match_color_name(hsv_color)
    
    def _match_color_name(self, hsv_color):
        """Match HSV color to color name"""
        h, s, v = hsv_color
        
        # Low saturation = white/gray/black
        if s < 30:
            if v > 200:
                return 'white'
            elif v < 50:
                return 'black'
            else:
                return 'gray'
        
        # Check pink first
        if 145 <= h <= 180 and 85 <= s <= 200 and v >= 100:
            return 'pink'
        
        # Check other colors
        for color_name, ranges in self.color_names.items():
            if color_name in ['white', 'gray', 'black', 'pink']:
                continue
            
            for i in range(0, len(ranges), 2):
                if i + 1 < len(ranges):
                    lower = ranges[i]
                    upper = ranges[i + 1]
                    
                    if (lower[0] <= h <= upper[0] and 
                        lower[1] <= s <= upper[1] and 
                        lower[2] <= v <= upper[2]):
                        return color_name
        
        # Fallback to hue-based
        if h < 15 or h > 157:
            return 'red' if s > 100 else 'pink'
        elif h < 30:
            return 'orange'
        elif h < 70:
            return 'yellow'
        elif h < 85:
            return 'green'
        elif h < 125:
            return 'blue'
        else:
            return 'purple'
    
    def create_annotated_image(self, image_path: str, circles=None, detections=None, output_path: str = None):
        """Create annotated image with detected objects"""
        img = cv2.imread(image_path)
        
        # Draw YOLO detections
        if detections is not None and len(detections) > 0:
            for detection in detections:
                x1, y1, x2, y2 = detection['bbox']
                confidence = detection.get('confidence', 0)
                
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                label = f"{confidence:.2f}"
                cv2.putText(img, label, (x1, y1 - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                
                center_x, center_y = detection['center']
                cv2.circle(img, (center_x, center_y), 3, (0, 0, 255), -1)
        
        # Draw circles (OpenCV detection)
        elif circles is not None and len(circles) > 0:
            for circle in circles:
                x, y, r = circle
                cv2.circle(img, (x, y), r, (0, 255, 0), 2)
                cv2.circle(img, (x, y), 2, (0, 0, 255), 3)
        
        if output_path:
            cv2.imwrite(output_path, img)
        return output_path if output_path else img
